======================================
LSTM EXPERIMENTS - OFFENSIVE LANGUAGE DETECTION
======================================

Starting GloVe experiments...

[1/6] Running: GloVe + Raw

============================================================
BILSTM CLASSIFIER FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Device: cpu
Embeddings: GLOVE (200d)
Preprocessing: raw
Hidden size: 128
Dropout: 0.3
Batch size: 32
Max length: 64

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

Loading GLOVE embeddings from embeddings/glove.twitter.27B.200d.txt...
Loaded 1193515 word vectors
Vocabulary size: 10883
Found 7090/10883 words in embeddings (65.1%)

Class weights: NOT=0.747, OFF=1.512

============================================================
INITIALIZING MODEL
============================================================
Total parameters: 2,515,034
Trainable parameters: 338,434

============================================================
TRAINING
============================================================
Epoch  1/15 | Loss: 0.6082 | Dev F1: 0.7004 | Dev Acc: 0.7160
  → New best model saved (F1: 0.7004)
Epoch  2/15 | Loss: 0.5499 | Dev F1: 0.6997 | Dev Acc: 0.7120
Epoch  3/15 | Loss: 0.5292 | Dev F1: 0.7196 | Dev Acc: 0.7430
  → New best model saved (F1: 0.7196)
Epoch  4/15 | Loss: 0.5075 | Dev F1: 0.6775 | Dev Acc: 0.6820
Epoch  5/15 | Loss: 0.4922 | Dev F1: 0.6971 | Dev Acc: 0.7130
Epoch  6/15 | Loss: 0.4645 | Dev F1: 0.6921 | Dev Acc: 0.7000

Early stopping at epoch 6

Loaded best model from results/best_lstm_glove_raw.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7430
  Macro F1:  0.7196
  F1 (OFF):  0.6385
  F1 (NOT):  0.8006

              precision    recall  f1-score   support

         NOT     0.8050    0.7963    0.8006       648
         OFF     0.6323    0.6449    0.6385       352

    accuracy                         0.7430      1000
   macro avg     0.7187    0.7206    0.7196      1000
weighted avg     0.7442    0.7430    0.7436      1000


Test Set:
  Accuracy:  0.7884
  Macro F1:  0.7336
  F1 (OFF):  0.6128
  F1 (NOT):  0.8544

              precision    recall  f1-score   support

         NOT     0.8476    0.8613    0.8544       620
         OFF     0.6261    0.6000    0.6128       240

    accuracy                         0.7884       860
   macro avg     0.7369    0.7306    0.7336       860
weighted avg     0.7858    0.7884    0.7870       860

Confusion matrix saved to confusion_matrix_bilstm_glove_dev.png
Confusion matrix saved to confusion_matrix_bilstm_glove_test.png

============================================================
PERFORMING ERROR ANALYSIS
============================================================

============================================================
ERROR ANALYSIS: BILSTM_GLOVE (raw)
============================================================

Total errors: 182/860 (21.2%)

Confusion patterns:
  OFF → NOT (false negatives): 96 (52.7% of errors)
  NOT → OFF (false positives): 86 (47.3% of errors)

High-confidence errors (conf > 0.8): 26

Error rate by text length:
  Very short (≤5): 18.2% (44 tweets)
  Short (6-10): 19.8% (101 tweets)
  Medium (11-20): 19.9% (246 tweets)
  Long (>20): 22.4% (469 tweets)
Detailed error analysis saved to: results//error_analysis_bilstm_glove_raw.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/glove_raw_lstm_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7196
Test F1:      0.7336
Test Acc:     0.7884

[2/6] Running: GloVe + Clean

============================================================
BILSTM CLASSIFIER FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Device: cpu
Embeddings: GLOVE (200d)
Preprocessing: clean
Hidden size: 128
Dropout: 0.3
Batch size: 32
Max length: 64

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

Loading GLOVE embeddings from embeddings/glove.twitter.27B.200d.txt...
Loaded 1193515 word vectors
Vocabulary size: 10880
Found 7091/10880 words in embeddings (65.2%)

Class weights: NOT=0.747, OFF=1.512

============================================================
INITIALIZING MODEL
============================================================
Total parameters: 2,514,434
Trainable parameters: 338,434

============================================================
TRAINING
============================================================
Epoch  1/15 | Loss: 0.6081 | Dev F1: 0.7146 | Dev Acc: 0.7510
  → New best model saved (F1: 0.7146)
Epoch  2/15 | Loss: 0.5498 | Dev F1: 0.7242 | Dev Acc: 0.7570
  → New best model saved (F1: 0.7242)
Epoch  3/15 | Loss: 0.5263 | Dev F1: 0.7274 | Dev Acc: 0.7600
  → New best model saved (F1: 0.7274)
Epoch  4/15 | Loss: 0.5074 | Dev F1: 0.6862 | Dev Acc: 0.6920
Epoch  5/15 | Loss: 0.4872 | Dev F1: 0.7273 | Dev Acc: 0.7380
Epoch  6/15 | Loss: 0.4609 | Dev F1: 0.7282 | Dev Acc: 0.7460
  → New best model saved (F1: 0.7282)
Epoch  7/15 | Loss: 0.4304 | Dev F1: 0.6877 | Dev Acc: 0.6950
Epoch  8/15 | Loss: 0.3953 | Dev F1: 0.7080 | Dev Acc: 0.7240
Epoch  9/15 | Loss: 0.3562 | Dev F1: 0.6899 | Dev Acc: 0.7070

Early stopping at epoch 9

Loaded best model from results/best_lstm_glove_clean.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7460
  Macro F1:  0.7282
  F1 (OFF):  0.6586
  F1 (NOT):  0.7978

              precision    recall  f1-score   support

         NOT     0.8240    0.7731    0.7978       648
         OFF     0.6250    0.6960    0.6586       352

    accuracy                         0.7460      1000
   macro avg     0.7245    0.7346    0.7282      1000
weighted avg     0.7540    0.7460    0.7488      1000


Test Set:
  Accuracy:  0.7698
  Macro F1:  0.7132
  F1 (OFF):  0.5858
  F1 (NOT):  0.8406

              precision    recall  f1-score   support

         NOT     0.8392    0.8419    0.8406       620
         OFF     0.5882    0.5833    0.5858       240

    accuracy                         0.7698       860
   macro avg     0.7137    0.7126    0.7132       860
weighted avg     0.7692    0.7698    0.7695       860

Confusion matrix saved to confusion_matrix_bilstm_glove_dev.png
Confusion matrix saved to confusion_matrix_bilstm_glove_test.png

============================================================
PERFORMING ERROR ANALYSIS
============================================================

============================================================
ERROR ANALYSIS: BILSTM_GLOVE (clean)
============================================================

Total errors: 198/860 (23.0%)

Confusion patterns:
  OFF → NOT (false negatives): 100 (50.5% of errors)
  NOT → OFF (false positives): 98 (49.5% of errors)

High-confidence errors (conf > 0.8): 52

Error rate by text length:
  Very short (≤5): 25.0% (52 tweets)
  Short (6-10): 17.6% (102 tweets)
  Medium (11-20): 17.9% (251 tweets)
  Long (>20): 26.8% (455 tweets)
Detailed error analysis saved to: results//error_analysis_bilstm_glove_clean.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/glove_clean_lstm_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7282
Test F1:      0.7132
Test Acc:     0.7698

[3/6] Running: GloVe + Aggressive

============================================================
BILSTM CLASSIFIER FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Device: cpu
Embeddings: GLOVE (200d)
Preprocessing: aggressive
Hidden size: 128
Dropout: 0.3
Batch size: 32
Max length: 64

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

Loading GLOVE embeddings from embeddings/glove.twitter.27B.200d.txt...
Loaded 1193515 word vectors
Vocabulary size: 8428
Found 8051/8428 words in embeddings (95.5%)

Class weights: NOT=0.747, OFF=1.512

============================================================
INITIALIZING MODEL
============================================================
Total parameters: 2,024,034
Trainable parameters: 338,434

============================================================
TRAINING
============================================================
Epoch  1/15 | Loss: 0.5835 | Dev F1: 0.7504 | Dev Acc: 0.7720
  → New best model saved (F1: 0.7504)
Epoch  2/15 | Loss: 0.5112 | Dev F1: 0.7132 | Dev Acc: 0.7210
Epoch  3/15 | Loss: 0.4846 | Dev F1: 0.7608 | Dev Acc: 0.7760
  → New best model saved (F1: 0.7608)
Epoch  4/15 | Loss: 0.4646 | Dev F1: 0.7529 | Dev Acc: 0.7750
Epoch  5/15 | Loss: 0.4408 | Dev F1: 0.7333 | Dev Acc: 0.7430
Epoch  6/15 | Loss: 0.4115 | Dev F1: 0.7504 | Dev Acc: 0.7690

Early stopping at epoch 6

Loaded best model from results/best_lstm_glove_aggressive.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7760
  Macro F1:  0.7608
  F1 (OFF):  0.7005
  F1 (NOT):  0.8211

              precision    recall  f1-score   support

         NOT     0.8510    0.7932    0.8211       648
         OFF     0.6616    0.7443    0.7005       352

    accuracy                         0.7760      1000
   macro avg     0.7563    0.7688    0.7608      1000
weighted avg     0.7843    0.7760    0.7787      1000


Test Set:
  Accuracy:  0.8012
  Macro F1:  0.7581
  F1 (OFF):  0.6559
  F1 (NOT):  0.8602

              precision    recall  f1-score   support

         NOT     0.8723    0.8484    0.8602       620
         OFF     0.6342    0.6792    0.6559       240

    accuracy                         0.8012       860
   macro avg     0.7533    0.7638    0.7581       860
weighted avg     0.8059    0.8012    0.8032       860

Confusion matrix saved to confusion_matrix_bilstm_glove_dev.png
Confusion matrix saved to confusion_matrix_bilstm_glove_test.png

============================================================
PERFORMING ERROR ANALYSIS
============================================================

============================================================
ERROR ANALYSIS: BILSTM_GLOVE (aggressive)
============================================================

Total errors: 171/860 (19.9%)

Confusion patterns:
  OFF → NOT (false negatives): 77 (45.0% of errors)
  NOT → OFF (false positives): 94 (55.0% of errors)

High-confidence errors (conf > 0.8): 73

Error rate by text length:
  Very short (≤5): 12.3% (57 tweets)
  Short (6-10): 12.5% (112 tweets)
  Medium (11-20): 18.0% (255 tweets)
  Long (>20): 23.9% (436 tweets)
Detailed error analysis saved to: results//error_analysis_bilstm_glove_aggressive.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/glove_aggressive_lstm_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7608
Test F1:      0.7581
Test Acc:     0.8012

Starting FastText experiments...

[4/6] Running: FastText + Raw

============================================================
BILSTM CLASSIFIER FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Device: cpu
Embeddings: FASTTEXT (300d)
Preprocessing: raw
Hidden size: 128
Dropout: 0.3
Batch size: 32
Max length: 64

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

Loading FASTTEXT embeddings from embeddings/fasttext-wiki-news-300d.txt...
Loaded 999999 word vectors
Vocabulary size: 10883
Found 8310/10883 words in embeddings (76.4%)

Class weights: NOT=0.747, OFF=1.512

============================================================
INITIALIZING MODEL
============================================================
Total parameters: 3,705,734
Trainable parameters: 440,834

============================================================
TRAINING
============================================================
Epoch  1/15 | Loss: 0.6553 | Dev F1: 0.6706 | Dev Acc: 0.6840
  → New best model saved (F1: 0.6706)
Epoch  2/15 | Loss: 0.5830 | Dev F1: 0.7037 | Dev Acc: 0.7190
  → New best model saved (F1: 0.7037)
Epoch  3/15 | Loss: 0.5557 | Dev F1: 0.7191 | Dev Acc: 0.7410
  → New best model saved (F1: 0.7191)
Epoch  4/15 | Loss: 0.5409 | Dev F1: 0.7031 | Dev Acc: 0.7180
Epoch  5/15 | Loss: 0.5291 | Dev F1: 0.7116 | Dev Acc: 0.7320
Epoch  6/15 | Loss: 0.5226 | Dev F1: 0.6983 | Dev Acc: 0.7110

Early stopping at epoch 6

Loaded best model from results/best_lstm_fasttext_raw.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7410
  Macro F1:  0.7191
  F1 (OFF):  0.6408
  F1 (NOT):  0.7975

              precision    recall  f1-score   support

         NOT     0.8082    0.7870    0.7975       648
         OFF     0.6260    0.6562    0.6408       352

    accuracy                         0.7410      1000
   macro avg     0.7171    0.7216    0.7191      1000
weighted avg     0.7441    0.7410    0.7423      1000


Test Set:
  Accuracy:  0.8000
  Macro F1:  0.7237
  F1 (OFF):  0.5784
  F1 (NOT):  0.8689

              precision    recall  f1-score   support

         NOT     0.8237    0.9194    0.8689       620
         OFF     0.7024    0.4917    0.5784       240

    accuracy                         0.8000       860
   macro avg     0.7630    0.7055    0.7237       860
weighted avg     0.7898    0.8000    0.7878       860

Confusion matrix saved to confusion_matrix_bilstm_fasttext_dev.png
Confusion matrix saved to confusion_matrix_bilstm_fasttext_test.png

============================================================
PERFORMING ERROR ANALYSIS
============================================================

============================================================
ERROR ANALYSIS: BILSTM_FASTTEXT (raw)
============================================================

Total errors: 172/860 (20.0%)

Confusion patterns:
  OFF → NOT (false negatives): 122 (70.9% of errors)
  NOT → OFF (false positives): 50 (29.1% of errors)

High-confidence errors (conf > 0.8): 12

Error rate by text length:
  Very short (≤5): 13.6% (44 tweets)
  Short (6-10): 22.8% (101 tweets)
  Medium (11-20): 16.7% (246 tweets)
  Long (>20): 21.7% (469 tweets)
Detailed error analysis saved to: results//error_analysis_bilstm_fasttext_raw.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/fasttext_raw_lstm_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7191
Test F1:      0.7237
Test Acc:     0.8000

[5/6] Running: FastText + Clean

============================================================
BILSTM CLASSIFIER FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Device: cpu
Embeddings: FASTTEXT (300d)
Preprocessing: clean
Hidden size: 128
Dropout: 0.3
Batch size: 32
Max length: 64

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

Loading FASTTEXT embeddings from embeddings/fasttext-wiki-news-300d.txt...
Loaded 999999 word vectors
Vocabulary size: 10880
Found 8311/10880 words in embeddings (76.4%)

Class weights: NOT=0.747, OFF=1.512

============================================================
INITIALIZING MODEL
============================================================
Total parameters: 3,704,834
Trainable parameters: 440,834

============================================================
TRAINING
============================================================
Epoch  1/15 | Loss: 0.6523 | Dev F1: 0.6946 | Dev Acc: 0.7170
  → New best model saved (F1: 0.6946)
Epoch  2/15 | Loss: 0.5939 | Dev F1: 0.7006 | Dev Acc: 0.7150
  → New best model saved (F1: 0.7006)
Epoch  3/15 | Loss: 0.5515 | Dev F1: 0.7210 | Dev Acc: 0.7540
  → New best model saved (F1: 0.7210)
Epoch  4/15 | Loss: 0.5376 | Dev F1: 0.7150 | Dev Acc: 0.7530
Epoch  5/15 | Loss: 0.5320 | Dev F1: 0.7183 | Dev Acc: 0.7390
Epoch  6/15 | Loss: 0.5176 | Dev F1: 0.7307 | Dev Acc: 0.7540
  → New best model saved (F1: 0.7307)
Epoch  7/15 | Loss: 0.5094 | Dev F1: 0.7210 | Dev Acc: 0.7430
Epoch  8/15 | Loss: 0.4976 | Dev F1: 0.7193 | Dev Acc: 0.7480
Epoch  9/15 | Loss: 0.4809 | Dev F1: 0.7126 | Dev Acc: 0.7300

Early stopping at epoch 9

Loaded best model from results/best_lstm_fasttext_clean.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7540
  Macro F1:  0.7307
  F1 (OFF):  0.6516
  F1 (NOT):  0.8099

              precision    recall  f1-score   support

         NOT     0.8111    0.8086    0.8099       648
         OFF     0.6497    0.6534    0.6516       352

    accuracy                         0.7540      1000
   macro avg     0.7304    0.7310    0.7307      1000
weighted avg     0.7543    0.7540    0.7542      1000


Test Set:
  Accuracy:  0.7953
  Macro F1:  0.7381
  F1 (OFF):  0.6157
  F1 (NOT):  0.8605

              precision    recall  f1-score   support

         NOT     0.8458    0.8758    0.8605       620
         OFF     0.6468    0.5875    0.6157       240

    accuracy                         0.7953       860
   macro avg     0.7463    0.7317    0.7381       860
weighted avg     0.7903    0.7953    0.7922       860

Confusion matrix saved to confusion_matrix_bilstm_fasttext_dev.png
Confusion matrix saved to confusion_matrix_bilstm_fasttext_test.png

============================================================
PERFORMING ERROR ANALYSIS
============================================================

============================================================
ERROR ANALYSIS: BILSTM_FASTTEXT (clean)
============================================================

Total errors: 176/860 (20.5%)

Confusion patterns:
  OFF → NOT (false negatives): 99 (56.2% of errors)
  NOT → OFF (false positives): 77 (43.8% of errors)

High-confidence errors (conf > 0.8): 19

Error rate by text length:
  Very short (≤5): 23.1% (52 tweets)
  Short (6-10): 20.6% (102 tweets)
  Medium (11-20): 16.7% (251 tweets)
  Long (>20): 22.2% (455 tweets)
Detailed error analysis saved to: results//error_analysis_bilstm_fasttext_clean.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/fasttext_clean_lstm_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7307
Test F1:      0.7381
Test Acc:     0.7953

[6/6] Running: FastText + Aggressive

============================================================
BILSTM CLASSIFIER FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Device: cpu
Embeddings: FASTTEXT (300d)
Preprocessing: aggressive
Hidden size: 128
Dropout: 0.3
Batch size: 32
Max length: 64

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

Loading FASTTEXT embeddings from embeddings/fasttext-wiki-news-300d.txt...
Loaded 999999 word vectors
Vocabulary size: 8428
Found 7942/8428 words in embeddings (94.2%)

Class weights: NOT=0.747, OFF=1.512

============================================================
INITIALIZING MODEL
============================================================
Total parameters: 2,969,234
Trainable parameters: 440,834

============================================================
TRAINING
============================================================
Epoch  1/15 | Loss: 0.6313 | Dev F1: 0.6908 | Dev Acc: 0.6990
  → New best model saved (F1: 0.6908)
Epoch  2/15 | Loss: 0.5330 | Dev F1: 0.7203 | Dev Acc: 0.7280
  → New best model saved (F1: 0.7203)
Epoch  3/15 | Loss: 0.5076 | Dev F1: 0.7220 | Dev Acc: 0.7300
  → New best model saved (F1: 0.7220)
Epoch  4/15 | Loss: 0.4934 | Dev F1: 0.7392 | Dev Acc: 0.7510
  → New best model saved (F1: 0.7392)
Epoch  5/15 | Loss: 0.4816 | Dev F1: 0.7467 | Dev Acc: 0.7790
  → New best model saved (F1: 0.7467)
Epoch  6/15 | Loss: 0.4737 | Dev F1: 0.7471 | Dev Acc: 0.7590
  → New best model saved (F1: 0.7471)
Epoch  7/15 | Loss: 0.4643 | Dev F1: 0.7496 | Dev Acc: 0.7740
  → New best model saved (F1: 0.7496)
Epoch  8/15 | Loss: 0.4514 | Dev F1: 0.7303 | Dev Acc: 0.7470
Epoch  9/15 | Loss: 0.4412 | Dev F1: 0.7081 | Dev Acc: 0.7190
Epoch 10/15 | Loss: 0.4318 | Dev F1: 0.7173 | Dev Acc: 0.7320

Early stopping at epoch 10

Loaded best model from results/best_lstm_fasttext_aggressive.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7740
  Macro F1:  0.7496
  F1 (OFF):  0.6715
  F1 (NOT):  0.8277

              precision    recall  f1-score   support

         NOT     0.8178    0.8380    0.8277       648
         OFF     0.6875    0.6562    0.6715       352

    accuracy                         0.7740      1000
   macro avg     0.7526    0.7471    0.7496      1000
weighted avg     0.7719    0.7740    0.7728      1000


Test Set:
  Accuracy:  0.8105
  Macro F1:  0.7544
  F1 (OFF):  0.6370
  F1 (NOT):  0.8718

              precision    recall  f1-score   support

         NOT     0.8510    0.8935    0.8718       620
         OFF     0.6842    0.5958    0.6370       240

    accuracy                         0.8105       860
   macro avg     0.7676    0.7447    0.7544       860
weighted avg     0.8045    0.8105    0.8062       860

Confusion matrix saved to confusion_matrix_bilstm_fasttext_dev.png
Confusion matrix saved to confusion_matrix_bilstm_fasttext_test.png

============================================================
PERFORMING ERROR ANALYSIS
============================================================

============================================================
ERROR ANALYSIS: BILSTM_FASTTEXT (aggressive)
============================================================

Total errors: 163/860 (19.0%)

Confusion patterns:
  OFF → NOT (false negatives): 97 (59.5% of errors)
  NOT → OFF (false positives): 66 (40.5% of errors)

High-confidence errors (conf > 0.8): 44

Error rate by text length:
  Very short (≤5): 15.8% (57 tweets)
  Short (6-10): 14.3% (112 tweets)
  Medium (11-20): 16.9% (255 tweets)
  Long (>20): 21.8% (436 tweets)
Detailed error analysis saved to: results//error_analysis_bilstm_fasttext_aggressive.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/fasttext_aggressive_lstm_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7496
Test F1:      0.7544
Test Acc:     0.8105

======================================
ALL LSTM EXPERIMENTS COMPLETED
======================================

Results CSVs:

Error analysis reports:

Name
----
error_analysis_bilstm_fasttext_aggressive.txt
error_analysis_bilstm_fasttext_clean.txt
error_analysis_bilstm_fasttext_raw.txt
error_analysis_bilstm_glove_aggressive.txt
error_analysis_bilstm_glove_clean.txt
error_analysis_bilstm_glove_raw.txt



Predictions files:

Name
----
predictions_bilstm_fasttext_aggressive.csv
predictions_bilstm_fasttext_clean.csv
predictions_bilstm_fasttext_raw.csv
predictions_bilstm_glove_aggressive.csv
predictions_bilstm_glove_clean.csv
predictions_bilstm_glove_raw.csv



Confusion matrices:

Name
----
confusion_matrix_bilstm_fasttext_dev.png
confusion_matrix_bilstm_fasttext_test.png
confusion_matrix_bilstm_glove_dev.png
confusion_matrix_bilstm_glove_test.png



To visualize results, run:
  python scripts/visualize_results.py --pattern lstm