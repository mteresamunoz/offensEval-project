======================================
TRANSFORMER EXPERIMENTS - OFFENSIVE LANGUAGE DETECTION
DeBERTa-v3-base + BERTweet
======================================

Working directory: /gaueko1/users/mmartin/offensEval-project
Python: /gaueko1/users/mmartin/offensEval-project/venv/bin/python

Checking GPU...
GPU Available: True
GPU: Tesla V100-PCIE-32GB

======================================
EXPERIMENTS WITH DEBERTA-V3-BASE
======================================

[1/6] DeBERTa-v3 + Raw

============================================================
TRANSFORMER FINE-TUNING FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Model: microsoft/deberta-v3-base
Display name: DEBERTA-V3-BASE
Preprocessing: raw
Device: cuda
Batch size: 16
Learning rate: 2e-05
Max length: 128

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

============================================================
LOADING MODEL AND TOKENIZER
============================================================
Tokenizer loaded: DebertaV2TokenizerFast
Model parameters: 184,423,682
Total training steps: 3060
Warmup steps: 306

============================================================
TRAINING
============================================================

Epoch 1/4
Epoch  1/4 | Loss: 0.5097 | Dev F1: 0.7839 | Dev Acc: 0.8090
  → New best model saved (F1: 0.7839)

Epoch 2/4
Epoch  2/4 | Loss: 0.3862 | Dev F1: 0.7683 | Dev Acc: 0.8030

Epoch 3/4
Epoch  3/4 | Loss: 0.3020 | Dev F1: 0.7903 | Dev Acc: 0.8020
  → New best model saved (F1: 0.7903)

Epoch 4/4
Epoch  4/4 | Loss: 0.2279 | Dev F1: 0.7748 | Dev Acc: 0.7900

Loaded best model from results/best_deberta-v3-base_raw.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.8020
  Macro F1:  0.7903
  F1 (OFF):  0.7408
  F1 (NOT):  0.8398

              precision    recall  f1-score   support

         NOT     0.8827    0.8009    0.8398       648
         OFF     0.6869    0.8040    0.7408       352

    accuracy                         0.8020      1000
   macro avg     0.7848    0.8025    0.7903      1000
weighted avg     0.8137    0.8020    0.8050      1000


Test Set:
  Accuracy:  0.8267
  Macro F1:  0.7926
  F1 (OFF):  0.7084
  F1 (NOT):  0.8768

              precision    recall  f1-score   support

         NOT     0.8998    0.8548    0.8768       620
         OFF     0.6679    0.7542    0.7084       240

    accuracy                         0.8267       860
   macro avg     0.7839    0.8045    0.7926       860
weighted avg     0.8351    0.8267    0.8298       860

Confusion matrix saved to confusion_matrix_deberta-v3-base_dev.png
Confusion matrix saved to confusion_matrix_deberta-v3-base_test.png

============================================================
ERROR ANALYSIS: deberta-v3-base (raw)
============================================================

Total errors: 149/860 (17.3%)

Confusion patterns:
  OFF → NOT (false negatives): 59 (39.6%)
  NOT → OFF (false positives): 90 (60.4%)

High-confidence errors (conf > 0.8): 71

Error rate by text length:
  Very short (≤5): 15.9% (44 tweets)
  Short (6-10): 12.9% (101 tweets)
  Medium (11-20): 14.2% (246 tweets)
  Long (>20): 20.0% (469 tweets)
Detailed error analysis saved to: results//error_analysis_deberta-v3-base_raw.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/transformer_deberta-v3-base_raw_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7903
Test F1:      0.7926
Test Acc:     0.8267

[2/6] DeBERTa-v3 + Clean

============================================================
TRANSFORMER FINE-TUNING FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Model: microsoft/deberta-v3-base
Display name: DEBERTA-V3-BASE
Preprocessing: clean
Device: cuda
Batch size: 16
Learning rate: 2e-05
Max length: 128

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

============================================================
LOADING MODEL AND TOKENIZER
============================================================
Tokenizer loaded: DebertaV2TokenizerFast
Model parameters: 184,423,682
Total training steps: 3060
Warmup steps: 306

============================================================
TRAINING
============================================================

Epoch 1/4
Epoch  1/4 | Loss: 0.5060 | Dev F1: 0.7864 | Dev Acc: 0.8050
  → New best model saved (F1: 0.7864)

Epoch 2/4
Epoch  2/4 | Loss: 0.3781 | Dev F1: 0.7662 | Dev Acc: 0.8000

Epoch 3/4
Epoch  3/4 | Loss: 0.2893 | Dev F1: 0.7743 | Dev Acc: 0.7900

Early stopping at epoch 3

Loaded best model from results/best_deberta-v3-base_clean.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.8050
  Macro F1:  0.7864
  F1 (OFF):  0.7234
  F1 (NOT):  0.8494

              precision    recall  f1-score   support

         NOT     0.8501    0.8488    0.8494       648
         OFF     0.7224    0.7244    0.7234       352

    accuracy                         0.8050      1000
   macro avg     0.7862    0.7866    0.7864      1000
weighted avg     0.8051    0.8050    0.8051      1000


Test Set:
  Accuracy:  0.8558
  Macro F1:  0.8101
  F1 (OFF):  0.7169
  F1 (NOT):  0.9033

              precision    recall  f1-score   support

         NOT     0.8746    0.9339    0.9033       620
         OFF     0.7929    0.6542    0.7169       240

    accuracy                         0.8558       860
   macro avg     0.8338    0.7940    0.8101       860
weighted avg     0.8518    0.8558    0.8513       860

Confusion matrix saved to confusion_matrix_deberta-v3-base_dev.png
Confusion matrix saved to confusion_matrix_deberta-v3-base_test.png

============================================================
ERROR ANALYSIS: deberta-v3-base (clean)
============================================================

Total errors: 124/860 (14.4%)

Confusion patterns:
  OFF → NOT (false negatives): 83 (66.9%)
  NOT → OFF (false positives): 41 (33.1%)

High-confidence errors (conf > 0.8): 63

Error rate by text length:
  Very short (≤5): 13.5% (52 tweets)
  Short (6-10): 11.8% (102 tweets)
  Medium (11-20): 12.7% (251 tweets)
  Long (>20): 16.0% (455 tweets)
Detailed error analysis saved to: results//error_analysis_deberta-v3-base_clean.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/transformer_deberta-v3-base_clean_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7864
Test F1:      0.8101
Test Acc:     0.8558

[3/6] DeBERTa-v3 + Aggressive

============================================================
TRANSFORMER FINE-TUNING FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Model: microsoft/deberta-v3-base
Display name: DEBERTA-V3-BASE
Preprocessing: aggressive
Device: cuda
Batch size: 16
Learning rate: 2e-05
Max length: 128

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

============================================================
LOADING MODEL AND TOKENIZER
============================================================
Tokenizer loaded: DebertaV2TokenizerFast
Model parameters: 184,423,682
Total training steps: 3060
Warmup steps: 306

============================================================
TRAINING
============================================================

Epoch 1/4
Epoch  1/4 | Loss: 0.5064 | Dev F1: 0.7797 | Dev Acc: 0.8040
  → New best model saved (F1: 0.7797)

Epoch 2/4
Epoch  2/4 | Loss: 0.3877 | Dev F1: 0.7681 | Dev Acc: 0.7970

Epoch 3/4
Epoch  3/4 | Loss: 0.3089 | Dev F1: 0.7676 | Dev Acc: 0.7840

Early stopping at epoch 3

Loaded best model from results/best_deberta-v3-base_aggressive.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.8040
  Macro F1:  0.7797
  F1 (OFF):  0.7066
  F1 (NOT):  0.8529

              precision    recall  f1-score   support

         NOT     0.8304    0.8765    0.8529       648
         OFF     0.7468    0.6705    0.7066       352

    accuracy                         0.8040      1000
   macro avg     0.7886    0.7735    0.7797      1000
weighted avg     0.8010    0.8040    0.8014      1000


Test Set:
  Accuracy:  0.8593
  Macro F1:  0.8155
  F1 (OFF):  0.7256
  F1 (NOT):  0.9054

              precision    recall  f1-score   support

         NOT     0.8786    0.9339    0.9054       620
         OFF     0.7960    0.6667    0.7256       240

    accuracy                         0.8593       860
   macro avg     0.8373    0.8003    0.8155       860
weighted avg     0.8556    0.8593    0.8552       860

Confusion matrix saved to confusion_matrix_deberta-v3-base_dev.png
Confusion matrix saved to confusion_matrix_deberta-v3-base_test.png

============================================================
ERROR ANALYSIS: deberta-v3-base (aggressive)
============================================================

Total errors: 121/860 (14.1%)

Confusion patterns:
  OFF → NOT (false negatives): 80 (66.1%)
  NOT → OFF (false positives): 41 (33.9%)

High-confidence errors (conf > 0.8): 61

Error rate by text length:
  Very short (≤5): 10.5% (57 tweets)
  Short (6-10): 10.7% (112 tweets)
  Medium (11-20): 12.2% (255 tweets)
  Long (>20): 16.5% (436 tweets)
Detailed error analysis saved to: results//error_analysis_deberta-v3-base_aggressive.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/transformer_deberta-v3-base_aggressive_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7797
Test F1:      0.8155
Test Acc:     0.8593

======================================
EXPERIMENTS WITH BERTWEET
======================================

[4/6] BERTweet + Raw

============================================================
TRANSFORMER FINE-TUNING FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Model: vinai/bertweet-base
Display name: BERTWEET-BASE
Preprocessing: raw
Device: cuda
Batch size: 16
Learning rate: 2e-05
Max length: 128

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

============================================================
LOADING MODEL AND TOKENIZER
============================================================
Tokenizer loaded: BertweetTokenizer
Model parameters: 134,901,506
Total training steps: 3060
Warmup steps: 306

============================================================
TRAINING
============================================================

Epoch 1/4
Epoch  1/4 | Loss: 0.5106 | Dev F1: 0.7699 | Dev Acc: 0.7910
  → New best model saved (F1: 0.7699)

Epoch 2/4
Epoch  2/4 | Loss: 0.3867 | Dev F1: 0.7618 | Dev Acc: 0.7740

Epoch 3/4
Epoch  3/4 | Loss: 0.3003 | Dev F1: 0.7667 | Dev Acc: 0.7820

Early stopping at epoch 3

Loaded best model from results/best_bertweet-base_raw.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7910
  Macro F1:  0.7699
  F1 (OFF):  0.7001
  F1 (NOT):  0.8396

              precision    recall  f1-score   support

         NOT     0.8351    0.8441    0.8396       648
         OFF     0.7072    0.6932    0.7001       352

    accuracy                         0.7910      1000
   macro avg     0.7712    0.7687    0.7699      1000
weighted avg     0.7901    0.7910    0.7905      1000


Test Set:
  Accuracy:  0.8477
  Macro F1:  0.8014
  F1 (OFF):  0.7056
  F1 (NOT):  0.8973

              precision    recall  f1-score   support

         NOT     0.8733    0.9226    0.8973       620
         OFF     0.7659    0.6542    0.7056       240

    accuracy                         0.8477       860
   macro avg     0.8196    0.7884    0.8014       860
weighted avg     0.8433    0.8477    0.8438       860

Confusion matrix saved to confusion_matrix_bertweet-base_dev.png
Confusion matrix saved to confusion_matrix_bertweet-base_test.png

============================================================
ERROR ANALYSIS: bertweet-base (raw)
============================================================

Total errors: 131/860 (15.2%)

Confusion patterns:
  OFF → NOT (false negatives): 83 (63.4%)
  NOT → OFF (false positives): 48 (36.6%)

High-confidence errors (conf > 0.8): 48

Error rate by text length:
  Very short (≤5): 9.1% (44 tweets)
  Short (6-10): 15.8% (101 tweets)
  Medium (11-20): 13.8% (246 tweets)
  Long (>20): 16.4% (469 tweets)
Detailed error analysis saved to: results//error_analysis_bertweet-base_raw.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/transformer_bertweet-base_raw_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7699
Test F1:      0.8014
Test Acc:     0.8477

[5/6] BERTweet + Clean

============================================================
TRANSFORMER FINE-TUNING FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Model: vinai/bertweet-base
Display name: BERTWEET-BASE
Preprocessing: clean
Device: cuda
Batch size: 16
Learning rate: 2e-05
Max length: 128

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

============================================================
LOADING MODEL AND TOKENIZER
============================================================
Tokenizer loaded: BertweetTokenizer
Model parameters: 134,901,506
Total training steps: 3060
Warmup steps: 306

============================================================
TRAINING
============================================================

Epoch 1/4
Epoch  1/4 | Loss: 0.5115 | Dev F1: 0.7736 | Dev Acc: 0.7910
  → New best model saved (F1: 0.7736)

Epoch 2/4
Epoch  2/4 | Loss: 0.3826 | Dev F1: 0.7557 | Dev Acc: 0.7630

Epoch 3/4
Epoch  3/4 | Loss: 0.2948 | Dev F1: 0.7676 | Dev Acc: 0.7840

Early stopping at epoch 3

Loaded best model from results/best_bertweet-base_clean.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7910
  Macro F1:  0.7736
  F1 (OFF):  0.7109
  F1 (NOT):  0.8363

              precision    recall  f1-score   support

         NOT     0.8490    0.8241    0.8363       648
         OFF     0.6927    0.7301    0.7109       352

    accuracy                         0.7910      1000
   macro avg     0.7708    0.7771    0.7736      1000
weighted avg     0.7940    0.7910    0.7922      1000


Test Set:
  Accuracy:  0.8500
  Macro F1:  0.8089
  F1 (OFF):  0.7202
  F1 (NOT):  0.8975

              precision    recall  f1-score   support

         NOT     0.8842    0.9113    0.8975       620
         OFF     0.7511    0.6917    0.7202       240

    accuracy                         0.8500       860
   macro avg     0.8177    0.8015    0.8089       860
weighted avg     0.8471    0.8500    0.8480       860

Confusion matrix saved to confusion_matrix_bertweet-base_dev.png
Confusion matrix saved to confusion_matrix_bertweet-base_test.png

============================================================
ERROR ANALYSIS: bertweet-base (clean)
============================================================

Total errors: 129/860 (15.0%)

Confusion patterns:
  OFF → NOT (false negatives): 74 (57.4%)
  NOT → OFF (false positives): 55 (42.6%)

High-confidence errors (conf > 0.8): 52

Error rate by text length:
  Very short (≤5): 17.3% (52 tweets)
  Short (6-10): 10.8% (102 tweets)
  Medium (11-20): 13.1% (251 tweets)
  Long (>20): 16.7% (455 tweets)
Detailed error analysis saved to: results//error_analysis_bertweet-base_clean.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/transformer_bertweet-base_clean_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7736
Test F1:      0.8089
Test Acc:     0.8500

[6/6] BERTweet + Aggressive

============================================================
TRANSFORMER FINE-TUNING FOR OFFENSIVE LANGUAGE DETECTION
============================================================
Model: vinai/bertweet-base
Display name: BERTWEET-BASE
Preprocessing: aggressive
Device: cuda
Batch size: 16
Learning rate: 2e-05
Max length: 128

============================================================
LOADING DATA
============================================================
Train: 12240 examples
Dev: 1000 examples
Test: 860 examples
Class distribution (train): {'NOT': np.int64(8192), 'OFF': np.int64(4048)}

============================================================
LOADING MODEL AND TOKENIZER
============================================================
Tokenizer loaded: BertweetTokenizer
Model parameters: 134,901,506
Total training steps: 3060
Warmup steps: 306

============================================================
TRAINING
============================================================

Epoch 1/4
Epoch  1/4 | Loss: 0.5028 | Dev F1: 0.7753 | Dev Acc: 0.7970
  → New best model saved (F1: 0.7753)

Epoch 2/4
Epoch  2/4 | Loss: 0.3817 | Dev F1: 0.7593 | Dev Acc: 0.7680

Epoch 3/4
Epoch  3/4 | Loss: 0.2969 | Dev F1: 0.7668 | Dev Acc: 0.7800

Early stopping at epoch 3

Loaded best model from results/best_bertweet-base_aggressive.pt

============================================================
FINAL EVALUATION
============================================================

Development Set:
  Accuracy:  0.7970
  Macro F1:  0.7753
  F1 (OFF):  0.7054
  F1 (NOT):  0.8452

              precision    recall  f1-score   support

         NOT     0.8356    0.8549    0.8452       648
         OFF     0.7211    0.6903    0.7054       352

    accuracy                         0.7970      1000
   macro avg     0.7783    0.7726    0.7753      1000
weighted avg     0.7953    0.7970    0.7960      1000


Test Set:
  Accuracy:  0.8407
  Macro F1:  0.7947
  F1 (OFF):  0.6976
  F1 (NOT):  0.8919

              precision    recall  f1-score   support

         NOT     0.8733    0.9113    0.8919       620
         OFF     0.7418    0.6583    0.6976       240

    accuracy                         0.8407       860
   macro avg     0.8075    0.7848    0.7947       860
weighted avg     0.8366    0.8407    0.8376       860

Confusion matrix saved to confusion_matrix_bertweet-base_dev.png
Confusion matrix saved to confusion_matrix_bertweet-base_test.png

============================================================
ERROR ANALYSIS: bertweet-base (aggressive)
============================================================

Total errors: 137/860 (15.9%)

Confusion patterns:
  OFF → NOT (false negatives): 82 (59.9%)
  NOT → OFF (false positives): 55 (40.1%)

High-confidence errors (conf > 0.8): 59

Error rate by text length:
  Very short (≤5): 19.3% (57 tweets)
  Short (6-10): 9.8% (112 tweets)
  Medium (11-20): 16.1% (255 tweets)
  Long (>20): 17.0% (436 tweets)
Detailed error analysis saved to: results//error_analysis_bertweet-base_aggressive.txt

============================================================
SAVING RESULTS
============================================================
Results saved to: results/transformer_bertweet-base_aggressive_results.csv

============================================================
EXPERIMENT COMPLETED
============================================================
Best dev F1:  0.7753
Test F1:      0.7947
Test Acc:     0.8407

======================================
ALL EXPERIMENTS COMPLETED
======================================

Results summary:

DeBERTa-v3-base results:
-rw-r--r-- 1 mmartin jirxuxen 174 Oct 28 21:16 results/transformer_deberta-v3-base_aggressive_results.csv
-rw-r--r-- 1 mmartin jirxuxen 170 Oct 28 21:08 results/transformer_deberta-v3-base_clean_results.csv
-rw-r--r-- 1 mmartin jirxuxen 168 Oct 28 21:01 results/transformer_deberta-v3-base_raw_results.csv

BERTweet results:
-rw-r--r-- 1 mmartin jirxuxen 173 Oct 28 21:33 results/transformer_bertweet-base_aggressive_results.csv
-rw-r--r-- 1 mmartin jirxuxen 152 Oct 28 21:27 results/transformer_bertweet-base_clean_results.csv
-rw-r--r-- 1 mmartin jirxuxen 166 Oct 28 21:22 results/transformer_bertweet-base_raw_results.csv

✅ DONE!
